{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "category\n",
      "Health        9958\n",
      "Society       9935\n",
      "Shopping      9928\n",
      "Sports        9895\n",
      "Computers     9883\n",
      "Science       9800\n",
      "Reference     9773\n",
      "Recreation    9764\n",
      "Adult         9424\n",
      "Games         6335\n",
      "News          4391\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "\n",
    "# Establish connection using SQLAlchemy\n",
    "engine = create_engine('postgresql+psycopg2://postgres:password@localhost:5432/dataset_bakalarka')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT url, content, category\n",
    "FROM web_data\n",
    "WHERE url IN (SELECT url FROM web_features);\n",
    "\"\"\"\n",
    "\n",
    "chunks = []\n",
    "for chunk in pd.read_sql_query(query, engine, chunksize=10000):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "print(df['category'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melou\\AppData\\Local\\Temp\\ipykernel_200\\151787263.py:4: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  return BeautifulSoup(text, \"lxml\").get_text(separator=\" \")\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(text):\n",
    "    return BeautifulSoup(text, \"lxml\").get_text(separator=\" \")\n",
    "\n",
    "df['clean_content'] = df['content'].apply(clean_html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU enabled: True\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melou\\AppData\\Local\\Temp\\ipykernel_200\\160055875.py:31: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(html, \"lxml\")\n"
     ]
    }
   ],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "import spacy\n",
    "\n",
    "is_gpu_enabled = spacy.require_gpu()\n",
    "print(f\"Is GPU enabled: {is_gpu_enabled}\")\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.max_length = 4000000\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text) if text is not None else \"\"\n",
    "    doc = nlp(text)\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "\n",
    "\n",
    "AdultKeywords = ['porn', 'videos', 'sex', 'xhamster', 'amateur', 'gay', 'straight', 'fuck', 'teen', 'ass', 'cock', 'czech', 'anal', 'shemale', 'girl', 'tits', 'blowjob', 'milf', 'asian', 'pussy', 'premium', 'black', 'hot', 'hardcore', 'cum', 'pornstars', 'blonde', 'brunette', 'dick', 'cumshot', 'solo', 'republic', 'interracial', 'pornstar', 'porno', 'exclusive', 'mature', 'handjob', 'lesbian', 'pov', 'wife', 'webcam', 'creampie', 'masturbation', 'brazzers', 'fetish', 'ebony', 'latina', 'orgasm', 'cam', 'watch', 'gangbang', 'japanese', 'guy', 'gifs', 'threesome', 'verified', 'categories', 'fucks', 'embed', 'bbw', 'category', 'love', 'lingerie', 'english', 'toy', 'fisting', 'homemade', 'redhead', 'pornhubcom', 'babe', 'stockings', 'hentai', 'indian', 'sexy', 'movie', 'favorite', 'hard', 'bdsm', 'model', 'playlist', 'femdom', 'fucking', 'pornhub', 'discover', 'rated', 'channels', 'step', 'upload', 'outdoor', 'horny', 'huge', 'twink', 'albums', 'facial', 'massage', 'latin', 'xxx', 'reality', 'bbc']\n",
    "ComputersKeywords = ['software', 'download', 'solution', 'file', 'services', 'company', 'online', 'technology', 'version', 'development', 'data', 'security', 'application', 'code', 'tool', 'copyright', 'solutions', 'windows', 'build', 'network', 'base', 'server', 'source', 'cloud', 'internet', 'mobile', 'check', 'linux', 'faq', 'database', 'mail', 'documentation', 'host', 'developer', 'technical', 'log', 'programming', 'guide', 'interface', 'standard', 'connect', 'close', 'mac', 'current', 'domain', 'hardware', 'theme', 'advanced', 'key', 'integration', 'virtual', 'automation', 'desktop', 'print', 'model', 'powerful', 'tools', 'class', 'article', 'java', 'package', 'machine', 'bug', 'display', 'api', 'engine', 'testing', 'tech', 'editor', 'environment', 'screen', 'javascript', 'suite', 'multiple', 'collection', 'field', 'size', 'communication', 'template', 'storage', 'plugin', 'multi', 'install', 'remote', 'module', 'ready', 'bit', 'directory', 'upgrade', 'tutorial', 'android', 'printer', 'script', 'implement', 'window', 'usb', 'excel', 'sql', 'xml', 'joomla']\n",
    "GamesKeywords = ['game', 'play', 'games', 'online', 'download', 'player', 'forum', 'version', 'copyright', 'casino', 'create', 'club', 'check', 'gaming', 'community', 'team', 'server', 'character', 'win', 'bridge', 'chess', 'tournament', 'puzzle', 'level', 'fantasy', 'war', 'poker', 'development', 'adventure', 'friend', 'wiki', 'rules', 'rpg', 'battle', 'strategy', 'arcade', 'season', 'magic', 'virtual', 'guild', 'nintendo', 'league', 'quest', 'role', 'challenge', 'patch', 'clan', 'chat', 'dragon', 'xbox', 'discord', 'score', 'slot', 'campaign', 'combat', 'pinball', 'fight', 'mod', 'wars', 'winner', 'playing', 'mode', 'bonus', 'multiplayer', 'weapon', 'mission', 'universe', 'tournaments', 'sports', 'beta', 'major', 'playstation', 'players', 'key', 'award', 'dice', 'wow', 'dungeon', 'upgrade', 'kill', 'cheat', 'steam', 'lottery', 'sudoku', 'betting', 'blue', 'gambling', 'gameplay', 'bingo', 'warcraft', 'expansion', 'hero', 'solitaire', 'increase', 'armor', 'beat', 'sims', 'blackjack', 'minecraft', 'collector']\n",
    "HealthKeywords = ['patient', 'services', 'medical', 'treatment', 'pet', 'medicine', 'therapy', 'donate', 'hospital', 'surgery', 'volunteer', 'cancer', 'clinical', 'appointment', 'child', 'disease', 'veterinary', 'emergency', 'clinic', 'pain', 'safety', 'animal', 'body', 'doctor', 'virtual', 'healthcare', 'eye', 'woman', 'check', 'donation', 'recovery', 'healing', 'journal', 'physician', 'nursing', 'heart', 'adult', 'healthy', 'disorder', 'wellness', 'vision', 'provider', 'drug', 'safe', 'treat', 'insurance', 'awareness', 'institute', 'prevention', 'breast', 'loss', 'primary', 'foot', 'physical', 'skin', 'dental', 'stress', 'pregnancy', 'acupuncture', 'vaccine', 'nurse', 'nutrition', 'cat', 'dog', 'testing', 'risk', 'injury', 'addiction', 'surgical', 'ensure', 'weight', 'symptom', 'patients', 'anxiety', 'massage', 'diagnosis', 'consultation', 'women', 'syndrome', 'procedure', 'manage', 'brain', 'blood', 'rehabilitation', 'pharmacy', 'baby', 'laser', 'specialist', 'sleep', 'pediatric', 'medication', 'chronic', 'diet', 'hair', 'vet', 'fertility', 'surgeon', 'cell', 'plastic', 'cosmetic']\n",
    "NewsKeywords = ['sports', 'local', 'business', 'opinion', 'editor', 'edition', 'media', 'submit', 'online', 'obituaries', 'university', 'entertainment', 'weather', 'police', 'newspaper', 'travel', 'education', 'digital', 'game', 'events', 'culture', 'advertising', 'government', 'country', 'stories', 'editorial', 'magazine', 'advertise', 'president', 'article', 'american', 'trump', 'vaccine', 'journalism', 'district', 'company', 'council', 'archives', 'lifestyle', 'record', 'advertisement', 'baseball', 'law', 'international', 'coronavirus', 'election', 'market', 'canada', 'publish', 'politics', 'basketball', 'technology', 'result', 'listen', 'film', 'death', 'job', 'check', 'science', 'football', 'subscriber', 'current', 'legal', 'valley', 'industry', 'sell', 'access', 'awards', 'journalist', 'build', 'court', 'war', 'subscription', 'department', 'network', 'jobs', 'reporter', 'vote', 'road', 'crime', 'charge', 'lake', 'nation', 'age', 'hit', 'feel', 'development', 'resident', 'friend', 'river', 'grow', 'leader', 'official', 'person', 'car', 'light', 'bank', 'load', 'hotel', 'usd']\n",
    "RecreationKeywords = ['club', 'wine', 'dog', 'book', 'family', 'car', 'breed', 'travel', 'calendar', 'reserve', 'trip', 'guide', 'fishing', 'life', 'fun', 'love', 'map', 'special', 'training', 'road', 'river', 'tour', 'fly', 'activity', 'hunt', 'team', 'puppy', 'water', 'volunteer', 'boat', 'country', 'lake', 'adventure', 'stay', 'rescue', 'collection', 'food', 'friend', 'beer', 'field', 'wines', 'cat', 'hunting', 'bird', 'winery', 'canada', 'safety', 'dive', 'camping', 'mountain', 'ride', 'sailing', 'explore', 'fish', 'valley', 'air', 'drive', 'guest', 'beautiful', 'house', 'school', 'pet', 'yacht', 'trail', 'night', 'diving', 'australia', 'vineyard', 'california', 'equipment', 'flight', 'season', 'weekend', 'cover', 'resort', 'charter', 'spring', 'weather', 'cruise', 'sport', 'win', 'holiday', 'outdoor', 'discover', 'tours', 'race', 'region', 'tasting', 'animal', 'game', 'bear', 'wildlife', 'walk', 'sea', 'lodge', 'scuba', 'islands', 'hotel', 'destination', 'vacation']\n",
    "ReferenceKeywords = ['student', 'university', 'college', 'campus', 'education', 'schedule', 'faculty', 'programs', 'resources', 'library', 'graduate', 'students', 'study', 'learning', 'science', 'academic', 'alumni', 'book', 'class', 'collection', 'department', 'technology', 'undergraduate', 'admission', 'mission', 'studies', 'engineering', 'map', 'institute', 'degree', 'courses', 'teacher', 'exhibit', 'application', 'sciences', 'educational', 'global', 'academics', 'teaching', 'scholarship', 'alumnus', 'collections', 'master', 'registration', 'curriculum', 'hours', 'tuition', 'exhibition', 'professor', 'publications', 'scholarships', 'phd', 'image', 'facilities', 'word', 'teach', 'cultural', 'workshop', 'activities', 'archives', 'grant', 'classroom', 'programme', 'grow', 'catalog', 'academy', 'grade', 'maps', 'honor', 'classes', 'woman', 'institution', 'graduation', 'libraries', 'technical', 'journal', 'degrees', 'colleges', 'housing', 'accreditation', 'exam', 'commencement', 'prospective', 'equity', 'semester', 'athlete', 'postgraduate', 'dean', 'departments', 'math', 'mba', 'ncaa', 'biology', 'requirements', 'bachelor', 'physics', 'honors', 'diploma', 'minor', 'psychology']\n",
    "ScienceKeywords = ['science', 'resources', 'development', 'technology', 'analysis', 'water', 'data', 'study', 'life', 'environmental', 'engineering', 'journal', 'energy', 'scientific', 'testing', 'model', 'material', 'laboratory', 'technical', 'safety', 'institute', 'space', 'human', 'land', 'global', 'lab', 'plant', 'air', 'cell', 'environment', 'conservation', 'food', 'industrial', 'animal', 'method', 'sciences', 'natural', 'impact', 'gas', 'earth', 'registration', 'phd', 'box', 'production', 'physics', 'medical', 'theory', 'manufacturing', 'astronomy', 'volunteer', 'climate', 'chemical', 'function', 'scientist', 'nature', 'biology', 'measurement', 'watch', 'engineer', 'math', 'platform', 'processing', 'marine', 'weather', 'chemistry', 'record', 'australia', 'leadership', 'researcher', 'solar', 'effective', 'county', 'grant', 'specie', 'child', 'category', 'webinar', 'temperature', 'clinical', 'green', 'telescope', 'measure', 'sustainable', 'imaging', 'position', 'wildlife', 'launch', 'waste', 'protein', 'disease', 'dna', 'ocean', 'expand', 'force', 'soil', 'filter', 'molecular', 'organic', 'carbon', 'gene']\n",
    "ShoppingKeywords = ['products', 'sale', 'shipping', 'store', 'stock', 'purchase', 'delivery', 'shopping', 'ship', 'catalog', 'services', 'supply', 'items', 'wholesale', 'checkout', 'category', 'craft', 'pack', 'tool', 'supplies', 'payment', 'produce', 'returns', 'plant', 'categories', 'discount', 'vintage', 'table', 'gear', 'limited', 'reviews', 'metal', 'basket', 'options', 'pet', 'brands', 'organic', 'wishlist', 'clothing', 'designer', 'faqs', 'fabric', 'leather', 'sets', 'sport', 'sports', 'kitchen', 'kids', 'package', 'manufacturer', 'apparel', 'beauty', 'shirt', 'shirts', 'bottle', 'sellers', 'cotton', 'toys', 'shoes', 'diamond', 'dress', 'chairs', 'baskets', 'boots', 'shoe', 'necklaces', 'plants', 'coat', 'dresses', 'womens']\n",
    "SocietyKeywords = ['church', 'worship', 'ministry', 'law', 'sunday', 'god', 'attorney', 'prayer', 'sermon', 'bible', 'parish', 'christ', 'methodist', 'school', 'community', 'jesus', 'firm', 'baptist', 'lawyer', 'legal', 'injury', 'catholic', 'pastor', 'faith', 'accident', 'service', 'christian', 'child', 'youth', 'client', 'funeral', 'yoga', 'mass', 'holy', 'mission', 'family', 'camp', 'presbyterian', 'lutheran', 'litigation', 'donate', 'event', 'united', 'love', 'lodge', 'life', 'online', 'spiritual', 'temple', 'student', 'jewish', 'estate', 'congregation', 'volunteer', 'woman', 'animal', 'jun', 'resource', 'practice', 'retreat', 'bulletin', 'bankruptcy', 'live', 'meeting', 'preschool', 'calendar', 'criminal', 'adult', 'county', 'personal', 'zoom', 'shabbat', 'book', 'study', 'justice', 'court', 'business', 'class', 'chapter', 'meditation', 'post', 'serve', 'divorce', 'patent', 'fellowship', 'gospel', 'association', 'connect', 'music', 'society', 'care', 'unitarian', 'international', 'wedding', 'district', 'saint', 'israel', 'episcopal', 'bishop', 'membership']\n",
    "SportsKeywords = ['golf', 'club', 'horse', 'league', 'race', 'soccer', 'ski', 'football', 'team', 'ride', 'tee', 'coach', 'player', 'bike', 'shot', 'martial', 'hockey', 'rugby', 'aikido', 'season', 'karate', 'ticket', 'class', 'junior', 'game', 'paintball', 'tournament', 'camp', 'play', 'event', 'trail', 'youth', 'hole', 'training', 'news', 'cycling', 'lesson', 'cup', 'academy', 'association', 'sport', 'schedule', 'stallion', 'championship', 'mountain', 'racing', 'sponsor', 'referee', 'tour', 'park', 'farm', 'skate', 'fixture', 'post', 'match', 'art', 'swimming', 'book', 'instructor', 'dojo', 'bicycle', 'country', 'tennis', 'fencing', 'marathon', 'registration', 'track', 'skating', 'surf', 'dressage', 'clubhouse', 'rider', 'swim', 'photo', 'bowling', 'champion', 'field', 'runner', 'run', 'resort', 'sale', 'goal', 'competition', 'trip', 'standing', 'forum', 'breed', 'cricket', 'canoe', 'ranch', 'winger', 'school', 'division', 'mare', 'summer', 'kayak', 'valley', 'save', 'river', 'bowl']\n",
    "\n",
    "def extract_meta_title(html):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
    "    title = soup.find('title')\n",
    "    meta_desc_content = str(meta_desc['content']) if meta_desc and 'content' in meta_desc.attrs else \"\"\n",
    "    title_content = str(title.get_text()) if title else \"\"\n",
    "    return meta_desc_content, title_content\n",
    "\n",
    "df[['meta_description', 'title']] = df['content'].apply(lambda x: pd.Series(extract_meta_title(x)))\n",
    "\n",
    "df['meta_description'] = df['meta_description'].apply(lemmatize_text)\n",
    "df['title'] = df['title'].apply(lemmatize_text)\n",
    "\n",
    "def keyword_percentage(text, keywords):\n",
    "    words = text.split()\n",
    "    keyword_count = sum(1 for word in words if word in keywords)\n",
    "    return (keyword_count / len(keywords)) * 100 if words else 0\n",
    "\n",
    "for column in ['meta_description', 'title']:\n",
    "    df[f'{column}_AdultKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, AdultKeywords))\n",
    "    df[f'{column}_ComputersKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, ComputersKeywords))\n",
    "    df[f'{column}_GamesKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, GamesKeywords))\n",
    "    df[f'{column}_HealthKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, HealthKeywords))\n",
    "    df[f'{column}_NewsKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, NewsKeywords))\n",
    "    df[f'{column}_RecreationKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, RecreationKeywords))\n",
    "    df[f'{column}_ReferenceKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, ReferenceKeywords))\n",
    "    df[f'{column}_ScienceKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, ScienceKeywords))\n",
    "    df[f'{column}_ShoppingKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, ShoppingKeywords))\n",
    "    df[f'{column}_SocietyKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, SocietyKeywords))\n",
    "    df[f'{column}_SportsKeywordPercentage'] = df[column].apply(lambda x: keyword_percentage(x, SportsKeywords))\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>title</th>\n",
       "      <th>meta_description_AdultKeywordPercentage</th>\n",
       "      <th>meta_description_ComputersKeywordPercentage</th>\n",
       "      <th>meta_description_GamesKeywordPercentage</th>\n",
       "      <th>meta_description_HealthKeywordPercentage</th>\n",
       "      <th>...</th>\n",
       "      <th>title_ComputersKeywordPercentage</th>\n",
       "      <th>title_GamesKeywordPercentage</th>\n",
       "      <th>title_HealthKeywordPercentage</th>\n",
       "      <th>title_NewsKeywordPercentage</th>\n",
       "      <th>title_RecreationKeywordPercentage</th>\n",
       "      <th>title_ReferenceKeywordPercentage</th>\n",
       "      <th>title_ScienceKeywordPercentage</th>\n",
       "      <th>title_ShoppingKeywordPercentage</th>\n",
       "      <th>title_SocietyKeywordPercentage</th>\n",
       "      <th>title_SportsKeywordPercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.readnotify.com</td>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "      <td>Computers</td>\n",
       "      <td>Certified email with delivery receipts, silent...</td>\n",
       "      <td>user get free return email notification , and/...</td>\n",
       "      <td>certified email with delivery receipt , silent...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.yanksarecoming.com</td>\n",
       "      <td>&lt;!doctype html&gt;\\n\\n&lt;!--[if lt IE 7]&gt;&lt;html lang...</td>\n",
       "      <td>Sports</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n \\n The Yanks Are Coming \\...</td>\n",
       "      <td>a trusted and independent voice on American So...</td>\n",
       "      <td>the Yanks be come</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>www.abai.org</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html&gt;\\n&lt;head&gt;\\n&lt;meta charset...</td>\n",
       "      <td>Health</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n \\n American Board of Alle...</td>\n",
       "      <td></td>\n",
       "      <td>American Board of Allergy and immunology :</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.augustana.org</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\r\\n&lt;html lang=\"en-US\"&gt;\\r\\n&lt;hea...</td>\n",
       "      <td>Society</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n Home - Augustana Lutheran...</td>\n",
       "      <td></td>\n",
       "      <td>home - Augustana Lutheran Church</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.dexcom.com</td>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\n&lt;html xmlns=\"http://www.w3.or...</td>\n",
       "      <td>Health</td>\n",
       "      <td>\\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\...</td>\n",
       "      <td>Dexcom Continuous Glucose Monitoring - discove...</td>\n",
       "      <td>Dexcom Continuous Glucose Monitoring | Dexcom CGM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url                                            content  \\\n",
       "0      www.readnotify.com  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...   \n",
       "1  www.yanksarecoming.com  <!doctype html>\\n\\n<!--[if lt IE 7]><html lang...   \n",
       "2            www.abai.org  <!DOCTYPE html>\\n<html>\\n<head>\\n<meta charset...   \n",
       "3       www.augustana.org  <!DOCTYPE html>\\r\\n<html lang=\"en-US\">\\r\\n<hea...   \n",
       "4          www.dexcom.com  <!DOCTYPE html>\\n<html xmlns=\"http://www.w3.or...   \n",
       "\n",
       "    category                                      clean_content  \\\n",
       "0  Computers  Certified email with delivery receipts, silent...   \n",
       "1     Sports  \\n \\n \\n \\n \\n \\n \\n \\n The Yanks Are Coming \\...   \n",
       "2     Health  \\n \\n \\n \\n \\n \\n \\n \\n American Board of Alle...   \n",
       "3    Society  \\n \\n \\n \\n \\n \\n \\n Home - Augustana Lutheran...   \n",
       "4     Health  \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\n \\...   \n",
       "\n",
       "                                    meta_description  \\\n",
       "0  user get free return email notification , and/...   \n",
       "1  a trusted and independent voice on American So...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Dexcom Continuous Glucose Monitoring - discove...   \n",
       "\n",
       "                                               title  \\\n",
       "0  certified email with delivery receipt , silent...   \n",
       "1                                  the Yanks be come   \n",
       "2         American Board of Allergy and immunology :   \n",
       "3                   home - Augustana Lutheran Church   \n",
       "4  Dexcom Continuous Glucose Monitoring | Dexcom CGM   \n",
       "\n",
       "   meta_description_AdultKeywordPercentage  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   meta_description_ComputersKeywordPercentage  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   meta_description_GamesKeywordPercentage  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   meta_description_HealthKeywordPercentage  ...  \\\n",
       "0                                       0.0  ...   \n",
       "1                                       0.0  ...   \n",
       "2                                       0.0  ...   \n",
       "3                                       0.0  ...   \n",
       "4                                       3.0  ...   \n",
       "\n",
       "   title_ComputersKeywordPercentage  title_GamesKeywordPercentage  \\\n",
       "0                               1.0                           0.0   \n",
       "1                               0.0                           0.0   \n",
       "2                               0.0                           0.0   \n",
       "3                               0.0                           0.0   \n",
       "4                               0.0                           0.0   \n",
       "\n",
       "   title_HealthKeywordPercentage  title_NewsKeywordPercentage  \\\n",
       "0                            0.0                          0.0   \n",
       "1                            0.0                          0.0   \n",
       "2                            0.0                          0.0   \n",
       "3                            0.0                          0.0   \n",
       "4                            0.0                          0.0   \n",
       "\n",
       "   title_RecreationKeywordPercentage  title_ReferenceKeywordPercentage  \\\n",
       "0                                0.0                               0.0   \n",
       "1                                0.0                               0.0   \n",
       "2                                0.0                               0.0   \n",
       "3                                0.0                               0.0   \n",
       "4                                0.0                               0.0   \n",
       "\n",
       "   title_ScienceKeywordPercentage  title_ShoppingKeywordPercentage  \\\n",
       "0                             0.0                         1.428571   \n",
       "1                             0.0                         0.000000   \n",
       "2                             0.0                         0.000000   \n",
       "3                             0.0                         0.000000   \n",
       "4                             0.0                         0.000000   \n",
       "\n",
       "   title_SocietyKeywordPercentage  title_SportsKeywordPercentage  \n",
       "0                             0.0                            0.0  \n",
       "1                             0.0                            0.0  \n",
       "2                             0.0                            0.0  \n",
       "3                             0.0                            0.0  \n",
       "4                             0.0                            0.0  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Initialize the scaler\n",
    "meta_title_scaler = MinMaxScaler()\n",
    "\n",
    "# Select the keyword percentage columns for meta description and title\n",
    "meta_title_keyword_columns = [f'{column}_{category}KeywordPercentage' for column in ['meta_description', 'title'] for category in ['Adult', 'Computers', 'Games', 'Health', 'News', 'Recreation', 'Reference', 'Science', 'Shopping', 'Society', 'Sports']]\n",
    "\n",
    "# Scale the keyword percentage features\n",
    "meta_title_keyword_features = meta_title_scaler.fit_transform(df[meta_title_keyword_columns])\n",
    "\n",
    "# Save the scaler to a file\n",
    "joblib.dump(meta_title_scaler, 'meta_title_scaler.joblib')\n",
    "meta_title_keyword_features = pd.DataFrame(meta_title_keyword_features, columns=meta_title_keyword_columns)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melou\\AppData\\Local\\Temp\\ipykernel_200\\3425665978.py:6: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(html, \"lxml\")\n"
     ]
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "def extract_html_features(html, base_url):\n",
    "    soup = BeautifulSoup(html, \"lxml\")\n",
    "    souptext = soup.get_text()\n",
    "    tags = [tag.name for tag in soup.find_all()]\n",
    "    unique_tags = len(set(tags))\n",
    "    h1_count = tags.count('h1')\n",
    "    h2_count = tags.count('h2')\n",
    "    h3_count = tags.count('h3')\n",
    "    paragraph_count = tags.count('p')\n",
    "    text_to_html_ratio = len(souptext) / len(html) if len(html) > 0 else 0\n",
    "    script_count = tags.count('script')\n",
    "    img_count = tags.count('img')\n",
    "    form_count = tags.count('form')\n",
    "    anchor_count = tags.count('a')\n",
    "    iframe_count = tags.count('iframe')\n",
    "    article_count = tags.count('article')\n",
    "    button_count = tags.count('button')\n",
    "\n",
    "    img_to_text_ratio = tags.count('img') / len(souptext) if len(souptext) > 0 else 0\n",
    "    meta_desc = soup.find('meta', attrs={'name': 'description'})\n",
    "    meta_desc_len = len(meta_desc['content']) if meta_desc and 'content' in meta_desc.attrs else 0\n",
    "\n",
    "    link_text = sum(len(tag.get_text()) for tag in soup.find_all('a'))\n",
    "    total_text = len(souptext)\n",
    "    link_density = link_text / total_text if total_text > 0 else 0\n",
    "\n",
    "    video_count = tags.count('video')\n",
    "    audio_count = tags.count('audio')\n",
    "\n",
    "    section_count = tags.count('section')\n",
    "    div_count = tags.count('div')\n",
    "\n",
    "    ul_count = tags.count('ul')\n",
    "    ol_count = tags.count('ol')\n",
    "\n",
    "    stylesheet_count = len(soup.find_all('link', {'rel': 'stylesheet'}))\n",
    "    external_script_count = len(soup.find_all('script', {'src': True}))\n",
    "\n",
    "    input_count = tags.count('input')\n",
    "    select_count = tags.count('select')\n",
    "    textarea_count = tags.count('textarea')\n",
    "    social_media_links_count = sum(1 for tag in soup.find_all('a', href=True) if \"facebook.com\" in tag['href'] or \"twitter.com\" in tag['href'] or \"instagram.com\" in tag['href'])\n",
    "    \n",
    "    return unique_tags, h1_count, h2_count, h3_count, paragraph_count, text_to_html_ratio, script_count, img_count, form_count, anchor_count, iframe_count, article_count, button_count, img_to_text_ratio, meta_desc_len, link_density, video_count, audio_count, section_count, div_count, ul_count, ol_count, stylesheet_count, external_script_count, input_count, select_count, textarea_count, social_media_links_count\n",
    "\n",
    "df[['unique_html_tags', 'h1_count', 'h2_count', 'h3_count', 'paragraph_count', 'text_to_html_ratio', 'script_count', 'img_count', 'form_count', 'anchor_count', 'iframe_count',\n",
    "     'article_count', 'button_count', 'img_to_text_ratio', 'meta_desc_len', 'link_density', 'video_count', 'audio_count', 'section_count', 'div_count',\n",
    "    'ul_count', 'ol_count', 'stylesheet_count', 'external_script_count', 'input_count', 'select_count', 'textarea_count', 'social_media_links_count']] = df.apply(lambda x: pd.Series(extract_html_features(x['content'], x['url'])), axis=1)\n",
    "\n",
    "def extract_text_features(text):\n",
    "    words = text.split()\n",
    "    word_count = len(words)\n",
    "    avg_word_length = sum(len(word) for word in words) / word_count if word_count > 0 else 0\n",
    "    unique_word_count = len(set(words))\n",
    "    return word_count, avg_word_length, unique_word_count\n",
    "\n",
    "df[['word_count', 'avg_word_length', 'unique_word_count']] = df['clean_content'].apply(lambda x: pd.Series(extract_text_features(x)))\n",
    "\n",
    "# Select the HTML and text feature columns\n",
    "html_text_feature_columns = ['unique_html_tags', 'h1_count', 'h2_count', 'h3_count', 'paragraph_count', 'text_to_html_ratio', \n",
    "                             'script_count', 'img_count', 'form_count', 'anchor_count', 'iframe_count', 'article_count', \n",
    "                             'button_count', 'img_to_text_ratio', 'meta_desc_len', 'link_density', 'video_count', 'audio_count', 'section_count', 'div_count', 'ul_count', 'ol_count', 'stylesheet_count', 'external_script_count',\n",
    "                             'input_count', 'select_count', 'textarea_count', 'social_media_links_count',\n",
    "                             'word_count', 'avg_word_length', 'unique_word_count']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gc\n",
    "\n",
    "html_scaler = MinMaxScaler()\n",
    "\n",
    "# Scale the HTML and text features\n",
    "html_text_features = html_scaler.fit_transform(df[html_text_feature_columns])\n",
    "\n",
    "joblib.dump(html_scaler, 'html_scaler.joblib')\n",
    "\n",
    "html_text_features = pd.DataFrame(html_text_features, columns=html_text_feature_columns)\n",
    "\n",
    "df.head()\n",
    "df['category'].value_counts()\n",
    "\n",
    "# Release the 'content' column from RAM as it is no longer needed\n",
    "df.drop(columns=['content'], inplace=True)\n",
    "\n",
    "# Garbage Collect\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>title</th>\n",
       "      <th>meta_description_AdultKeywordPercentage</th>\n",
       "      <th>meta_description_ComputersKeywordPercentage</th>\n",
       "      <th>meta_description_GamesKeywordPercentage</th>\n",
       "      <th>meta_description_HealthKeywordPercentage</th>\n",
       "      <th>meta_description_NewsKeywordPercentage</th>\n",
       "      <th>...</th>\n",
       "      <th>ol_count</th>\n",
       "      <th>stylesheet_count</th>\n",
       "      <th>external_script_count</th>\n",
       "      <th>input_count</th>\n",
       "      <th>select_count</th>\n",
       "      <th>textarea_count</th>\n",
       "      <th>social_media_links_count</th>\n",
       "      <th>word_count</th>\n",
       "      <th>avg_word_length</th>\n",
       "      <th>unique_word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.readnotify.com</td>\n",
       "      <td>Computers</td>\n",
       "      <td>certified delivery receipts silent tracking pr...</td>\n",
       "      <td>user get free return email notification , and/...</td>\n",
       "      <td>certified email with delivery receipt , silent...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>81.0</td>\n",
       "      <td>5.481481</td>\n",
       "      <td>72.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.yanksarecoming.com</td>\n",
       "      <td>Sports</td>\n",
       "      <td>yanks coming independent voice american soccer...</td>\n",
       "      <td>a trusted and independent voice on American So...</td>\n",
       "      <td>the Yanks be come</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>953.0</td>\n",
       "      <td>4.991605</td>\n",
       "      <td>320.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>www.abai.org</td>\n",
       "      <td>Health</td>\n",
       "      <td>american allergy immunology publications resou...</td>\n",
       "      <td></td>\n",
       "      <td>American Board of Allergy and immunology :</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>369.0</td>\n",
       "      <td>5.905149</td>\n",
       "      <td>225.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.augustana.org</td>\n",
       "      <td>Society</td>\n",
       "      <td>augustana lutheran church sermon children yout...</td>\n",
       "      <td></td>\n",
       "      <td>home - Augustana Lutheran Church</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>5.258876</td>\n",
       "      <td>391.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.dexcom.com</td>\n",
       "      <td>Health</td>\n",
       "      <td>dexcom continuous glucose monitoring dexcom cg...</td>\n",
       "      <td>Dexcom Continuous Glucose Monitoring - discove...</td>\n",
       "      <td>Dexcom Continuous Glucose Monitoring | Dexcom CGM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1798.0</td>\n",
       "      <td>13.898776</td>\n",
       "      <td>739.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url   category  \\\n",
       "0      www.readnotify.com  Computers   \n",
       "1  www.yanksarecoming.com     Sports   \n",
       "2            www.abai.org     Health   \n",
       "3       www.augustana.org    Society   \n",
       "4          www.dexcom.com     Health   \n",
       "\n",
       "                                       clean_content  \\\n",
       "0  certified delivery receipts silent tracking pr...   \n",
       "1  yanks coming independent voice american soccer...   \n",
       "2  american allergy immunology publications resou...   \n",
       "3  augustana lutheran church sermon children yout...   \n",
       "4  dexcom continuous glucose monitoring dexcom cg...   \n",
       "\n",
       "                                    meta_description  \\\n",
       "0  user get free return email notification , and/...   \n",
       "1  a trusted and independent voice on American So...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Dexcom Continuous Glucose Monitoring - discove...   \n",
       "\n",
       "                                               title  \\\n",
       "0  certified email with delivery receipt , silent...   \n",
       "1                                  the Yanks be come   \n",
       "2         American Board of Allergy and immunology :   \n",
       "3                   home - Augustana Lutheran Church   \n",
       "4  Dexcom Continuous Glucose Monitoring | Dexcom CGM   \n",
       "\n",
       "   meta_description_AdultKeywordPercentage  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   meta_description_ComputersKeywordPercentage  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   meta_description_GamesKeywordPercentage  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   meta_description_HealthKeywordPercentage  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       3.0   \n",
       "\n",
       "   meta_description_NewsKeywordPercentage  ...  ol_count  stylesheet_count  \\\n",
       "0                                     0.0  ...       0.0               0.0   \n",
       "1                                     0.0  ...       0.0              27.0   \n",
       "2                                     0.0  ...       0.0               7.0   \n",
       "3                                     0.0  ...       0.0              18.0   \n",
       "4                                     0.0  ...       0.0               7.0   \n",
       "\n",
       "   external_script_count  input_count  select_count  textarea_count  \\\n",
       "0                    2.0          8.0           0.0             0.0   \n",
       "1                   28.0          0.0           0.0             0.0   \n",
       "2                    6.0          4.0           0.0             0.0   \n",
       "3                   19.0          0.0           0.0             0.0   \n",
       "4                   13.0          0.0           0.0             0.0   \n",
       "\n",
       "   social_media_links_count  word_count  avg_word_length  unique_word_count  \n",
       "0                       0.0        81.0         5.481481               72.0  \n",
       "1                       6.0       953.0         4.991605              320.0  \n",
       "2                       2.0       369.0         5.905149              225.0  \n",
       "3                       2.0       676.0         5.258876              391.0  \n",
       "4                       0.0      1798.0        13.898776              739.0  \n",
       "\n",
       "[5 rows x 58 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "with open(\"stopwords-en.txt\", \"r\") as file:\n",
    "    stopwords_list = file.read().splitlines()\n",
    "\n",
    "stopwords = set(stopwords_list)\n",
    "custom_stopwords = set([\n",
    "    # First batch of words with no meaning\n",
    "    'contact', 'service', 'policy', 'site', 'privacy', 'support', 'email', 'blog',\n",
    "    'post', 'learn', 'read', 'offer', 'provide', 'include', 'click', 'update',\n",
    "    'feature', 'link', 'search', 'website', 'program', 'start', 'view', 'resource',\n",
    "    'experience', 'list', 'free', 'info', 'shop', 'video', 'share', 'member',\n",
    "    'add', 'start', 'work', 'order', 'day', 'people', 'history', 'office',\n",
    "    'time', 'year', 'event', 'national', 'state', 'high', 'month', 'week', 'open',\n",
    "    'cookies', 'menu', 'cart', 'browser', 'select', 'choose', 'hope', 'enjoy',\n",
    "\n",
    "    # Social media/web\n",
    "    'facebook', 'twitter', 'youtube', 'instagram', 'account', 'cookie', 'subscribe',\n",
    "    'newsletter', 'sign', 'message', 'comment', 'form', 'login', 'user', 'member',\n",
    "    'join', 'write', 'update', 'search', 'review',\n",
    "\n",
    "    # Dates\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august',\n",
    "    'september', 'october', 'november', 'december', 'year', 'today', 'yesterday', 'tomorrow', 'datum', 'date',\n",
    "    'jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec',\n",
    "\n",
    "    # Days of the week\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun',\n",
    "\n",
    "    # Places with no meaning\n",
    "    'regional', 'albuquerque', 'chicago', 'minneapolis', 'philadelphia', 'phoenix', 'rhode', 'island', 'scottsdale', 'washington', 'wisconsin', 'michigan',\n",
    "    'bay', 'beach', 'dakota', 'florida', 'georgia', 'hampshire', 'harbor', 'iowa', 'maine',  'missouri', 'park', 'virginia', 'vista', 'wisconsin', 'massachusetts',\n",
    "    'minnesota',\n",
    "\n",
    "    # Words holding no weight or too general to hold any\n",
    "    'skip', 'content', 'main', 'term', 'condition', 'toggle', 'navigation', 'wordpress', 'social', 'medium', 'upcoming', 'event',\n",
    "    'photo', 'gallery', 'news', 'frequently', 'question', 'ask', 'press', 'release', 'quick', 'link', 'continue', 'read', 'phone', 'fax', 'answer', 'question',\n",
    "    'board', 'director', 'real', 'estate', 'los', 'angeles', 'new', 'york', 'city', 'san', 'francisco', 'power', 'united', 'kingdom', 'states', 'america', 'fran', 'ais',\n",
    "    'north', 'carolina', 'las', 'vegas', 'annual', 'report', 'highly', 'recommend', 'rss', 'feed', 'white', 'paper', 'hong', 'kong', 'credit', 'card', 'mental', 'health', 'public', 'save', 'money',\n",
    "    'annual', 'meeting', 'wide', 'range', 'care', 'gift', 'professional', 'live', 'stream', 'quality', 'product', 'project', 'management', 'meet', 'nonprofit', 'organization', 'blogthis', 'pinter',\n",
    "    'design', 'success', 'story', 'summer', 'camp', 'chain', 'register', 'trademark', 'username', 'password', 'certificate', 'plan', 'visit', 'regular', 'price', 'covid', 'pandemic', 'south', 'africa', 'west', 'east', 'regional',\n",
    "])\n",
    "stopwords.update(custom_stopwords)\n",
    "stopwords = sorted(stopwords)\n",
    "\n",
    "def further_clean_text(text, stopwords):\n",
    "    # Normalize spaces; replaces all kinds of whitespace with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove all numbers (digits) from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove non-English characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Convert text to lower case to standardize for stopwords removal\n",
    "    text = text.lower()\n",
    "\n",
    "    # Split text into words, remove short words and stopwords\n",
    "    text = ' '.join([word for word in text.split() if len(word) >= 3 and word not in stopwords])\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['clean_content'] = df['clean_content'].apply(lambda x: further_clean_text(x, stopwords))\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU enabled: True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "is_gpu_enabled = spacy.require_gpu()\n",
    "print(f\"Is GPU enabled: {is_gpu_enabled}\")\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.max_length = 4000000\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    # Process the text through the spaCy NLP pipeline\n",
    "    doc = nlp(text)\n",
    "    # Return the lemmatized text\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "df['clean_content'] = df['clean_content'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "Health        9958\n",
       "Society       9935\n",
       "Shopping      9928\n",
       "Sports        9895\n",
       "Computers     9883\n",
       "Science       9800\n",
       "Reference     9773\n",
       "Recreation    9764\n",
       "Adult         9424\n",
       "Games         6335\n",
       "News          4391\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "html_text_features = pd.DataFrame(html_text_features, columns=html_text_feature_columns)\n",
    "meta_title_keyword_features = pd.DataFrame(meta_title_keyword_features, columns=meta_title_keyword_columns)\n",
    "\n",
    "df.head()\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic 0:\n",
      "english access playlist french month republic discover islands rate exclusive\n",
      "Topic 1:\n",
      "club golf team schedule league sport soccer final field football\n",
      "Topic 2:\n",
      "post church life comment book forum god music game worship\n",
      "Topic 3:\n",
      "video amateur sex cock hot category comment black photo fuck\n",
      "Topic 4:\n",
      "article science issue journal cell image publish model analysis book\n",
      "Topic 5:\n",
      "software datum solution download file version tool application create code\n",
      "Topic 6:\n",
      "event community membership resource donate association calendar volunteer museum online\n",
      "Topic 7:\n",
      "porn gay teen tit ass anal fuck milf shemale video\n",
      "Topic 8:\n",
      "view reply woman foot girl watch hair xhamster body javascript\n",
      "Topic 9:\n",
      "love friend leave lot month head happy play hard picture\n",
      "Topic 10:\n",
      "patient medical treatment pet dog surgery service hospital cancer medicine\n",
      "Topic 11:\n",
      "game race sport play win online local car horse player\n",
      "Topic 12:\n",
      "tour wine book trip food family travel river water lake\n",
      "Topic 13:\n",
      "student school university college education study program campus center graduate\n",
      "Topic 14:\n",
      "law business service client company personal legal process practice life\n",
      "Topic 15:\n",
      "product sale accessory item kit supply set customer custom equipment\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "\n",
    "LDACountvectorizer = CountVectorizer(max_df=0.9, min_df=50) \n",
    "X_counts = LDACountvectorizer.fit_transform(df['clean_content'])\n",
    "\n",
    "# Save the scaler to a file\n",
    "joblib.dump(LDACountvectorizer, 'LDACountvectorizer.joblib')\n",
    "\n",
    "vocab = LDACountvectorizer.get_feature_names_out()\n",
    "\n",
    "\n",
    "lda = LatentDirichletAllocation(n_components=16, max_iter=10, learning_method='online', random_state=42)\n",
    "X_topics = lda.fit_transform(X_counts)\n",
    "\n",
    "joblib.dump(lda, 'lda.joblib')\n",
    "\n",
    "# Display top words in topics\n",
    "def display_topics(model, feature_names, num_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(f\"Topic {topic_idx}:\")\n",
    "        print(\" \".join([feature_names[i] for i in topic.argsort()[:-num_words - 1:-1]]))\n",
    "\n",
    "display_topics(lda, vocab, 10)\n",
    "\n",
    "topic_features = pd.DataFrame(X_topics, columns=[f'Topic_{i}' for i in range(16)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>url</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_content</th>\n",
       "      <th>meta_description</th>\n",
       "      <th>title</th>\n",
       "      <th>meta_description_AdultKeywordPercentage</th>\n",
       "      <th>meta_description_ComputersKeywordPercentage</th>\n",
       "      <th>meta_description_GamesKeywordPercentage</th>\n",
       "      <th>meta_description_HealthKeywordPercentage</th>\n",
       "      <th>meta_description_NewsKeywordPercentage</th>\n",
       "      <th>...</th>\n",
       "      <th>ComputersKeywordPercentage</th>\n",
       "      <th>GamesKeywordPercentage</th>\n",
       "      <th>HealthKeywordPercentage</th>\n",
       "      <th>NewsKeywordPercentage</th>\n",
       "      <th>RecreationKeywordPercentage</th>\n",
       "      <th>ReferenceKeywordPercentage</th>\n",
       "      <th>ScienceKeywordPercentage</th>\n",
       "      <th>ShoppingKeywordPercentage</th>\n",
       "      <th>SocietyKeywordPercentage</th>\n",
       "      <th>SportsKeywordPercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>www.readnotify.com</td>\n",
       "      <td>Computers</td>\n",
       "      <td>certify delivery receipt silent track proofofo...</td>\n",
       "      <td>user get free return email notification , and/...</td>\n",
       "      <td>certified email with delivery receipt , silent...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>www.yanksarecoming.com</td>\n",
       "      <td>Sports</td>\n",
       "      <td>yank come independent voice american soccer ty...</td>\n",
       "      <td>a trusted and independent voice on American So...</td>\n",
       "      <td>the Yanks be come</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.0</td>\n",
       "      <td>22.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>www.abai.org</td>\n",
       "      <td>Health</td>\n",
       "      <td>american allergy immunology publication resour...</td>\n",
       "      <td></td>\n",
       "      <td>American Board of Allergy and immunology :</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.857143</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>www.augustana.org</td>\n",
       "      <td>Society</td>\n",
       "      <td>augustana lutheran church sermon child youth s...</td>\n",
       "      <td></td>\n",
       "      <td>home - Augustana Lutheran Church</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>80.0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>www.dexcom.com</td>\n",
       "      <td>Health</td>\n",
       "      <td>dexcom continuous glucose monitor dexcom cgm e...</td>\n",
       "      <td>Dexcom Continuous Glucose Monitoring - discove...</td>\n",
       "      <td>Dexcom Continuous Glucose Monitoring | Dexcom CGM</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.428571</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 69 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      url   category  \\\n",
       "0      www.readnotify.com  Computers   \n",
       "1  www.yanksarecoming.com     Sports   \n",
       "2            www.abai.org     Health   \n",
       "3       www.augustana.org    Society   \n",
       "4          www.dexcom.com     Health   \n",
       "\n",
       "                                       clean_content  \\\n",
       "0  certify delivery receipt silent track proofofo...   \n",
       "1  yank come independent voice american soccer ty...   \n",
       "2  american allergy immunology publication resour...   \n",
       "3  augustana lutheran church sermon child youth s...   \n",
       "4  dexcom continuous glucose monitor dexcom cgm e...   \n",
       "\n",
       "                                    meta_description  \\\n",
       "0  user get free return email notification , and/...   \n",
       "1  a trusted and independent voice on American So...   \n",
       "2                                                      \n",
       "3                                                      \n",
       "4  Dexcom Continuous Glucose Monitoring - discove...   \n",
       "\n",
       "                                               title  \\\n",
       "0  certified email with delivery receipt , silent...   \n",
       "1                                  the Yanks be come   \n",
       "2         American Board of Allergy and immunology :   \n",
       "3                   home - Augustana Lutheran Church   \n",
       "4  Dexcom Continuous Glucose Monitoring | Dexcom CGM   \n",
       "\n",
       "   meta_description_AdultKeywordPercentage  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   meta_description_ComputersKeywordPercentage  \\\n",
       "0                                          0.0   \n",
       "1                                          0.0   \n",
       "2                                          0.0   \n",
       "3                                          0.0   \n",
       "4                                          0.0   \n",
       "\n",
       "   meta_description_GamesKeywordPercentage  \\\n",
       "0                                      0.0   \n",
       "1                                      0.0   \n",
       "2                                      0.0   \n",
       "3                                      0.0   \n",
       "4                                      1.0   \n",
       "\n",
       "   meta_description_HealthKeywordPercentage  \\\n",
       "0                                       0.0   \n",
       "1                                       0.0   \n",
       "2                                       0.0   \n",
       "3                                       0.0   \n",
       "4                                       3.0   \n",
       "\n",
       "   meta_description_NewsKeywordPercentage  ...  ComputersKeywordPercentage  \\\n",
       "0                                     0.0  ...                         6.0   \n",
       "1                                     0.0  ...                         9.0   \n",
       "2                                     0.0  ...                         4.0   \n",
       "3                                     0.0  ...                         4.0   \n",
       "4                                     0.0  ...                        10.0   \n",
       "\n",
       "   GamesKeywordPercentage  HealthKeywordPercentage  NewsKeywordPercentage  \\\n",
       "0                     1.0                      0.0                    0.0   \n",
       "1                    31.0                      6.0                    7.0   \n",
       "2                     2.0                      6.0                    7.0   \n",
       "3                    12.0                      9.0                   10.0   \n",
       "4                     4.0                      2.0                    8.0   \n",
       "\n",
       "   RecreationKeywordPercentage  ReferenceKeywordPercentage  \\\n",
       "0                          0.0                         0.0   \n",
       "1                         15.0                         2.0   \n",
       "2                          3.0                         9.0   \n",
       "3                         12.0                         9.0   \n",
       "4                          6.0                         0.0   \n",
       "\n",
       "   ScienceKeywordPercentage  ShoppingKeywordPercentage  \\\n",
       "0                       0.0                   1.428571   \n",
       "1                       6.0                   0.000000   \n",
       "2                       3.0                   2.857143   \n",
       "3                      10.0                   0.000000   \n",
       "4                       2.0                   1.428571   \n",
       "\n",
       "   SocietyKeywordPercentage  SportsKeywordPercentage  \n",
       "0                       0.0                      1.0  \n",
       "1                       6.0                     22.0  \n",
       "2                       2.0                      2.0  \n",
       "3                      80.0                      9.0  \n",
       "4                       5.0                      0.0  \n",
       "\n",
       "[5 rows x 69 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AdultKeywords = ['porn', 'videos', 'sex', 'xhamster', 'amateur', 'gay', 'straight', 'fuck', 'teen', 'ass', 'cock', 'czech', 'anal', 'shemale', 'girl', 'tits', 'blowjob', 'milf', 'asian', 'pussy', 'premium', 'black', 'hot', 'hardcore', 'cum', 'pornstars', 'blonde', 'brunette', 'dick', 'cumshot', 'solo', 'republic', 'interracial', 'pornstar', 'porno', 'exclusive', 'mature', 'handjob', 'lesbian', 'pov', 'wife', 'webcam', 'creampie', 'masturbation', 'brazzers', 'fetish', 'ebony', 'latina', 'orgasm', 'cam', 'watch', 'gangbang', 'japanese', 'guy', 'gifs', 'threesome', 'verified', 'categories', 'fucks', 'embed', 'bbw', 'category', 'love', 'lingerie', 'english', 'toy', 'fisting', 'homemade', 'redhead', 'pornhubcom', 'babe', 'stockings', 'hentai', 'indian', 'sexy', 'movie', 'favorite', 'hard', 'bdsm', 'model', 'playlist', 'femdom', 'fucking', 'pornhub', 'discover', 'rated', 'channels', 'step', 'upload', 'outdoor', 'horny', 'huge', 'twink', 'albums', 'facial', 'massage', 'latin', 'xxx', 'reality', 'bbc']\n",
    "ComputersKeywords = ['software', 'download', 'solution', 'file', 'services', 'company', 'online', 'technology', 'version', 'development', 'data', 'security', 'application', 'code', 'tool', 'copyright', 'solutions', 'windows', 'build', 'network', 'base', 'server', 'source', 'cloud', 'internet', 'mobile', 'check', 'linux', 'faq', 'database', 'mail', 'documentation', 'host', 'developer', 'technical', 'log', 'programming', 'guide', 'interface', 'standard', 'connect', 'close', 'mac', 'current', 'domain', 'hardware', 'theme', 'advanced', 'key', 'integration', 'virtual', 'automation', 'desktop', 'print', 'model', 'powerful', 'tools', 'class', 'article', 'java', 'package', 'machine', 'bug', 'display', 'api', 'engine', 'testing', 'tech', 'editor', 'environment', 'screen', 'javascript', 'suite', 'multiple', 'collection', 'field', 'size', 'communication', 'template', 'storage', 'plugin', 'multi', 'install', 'remote', 'module', 'ready', 'bit', 'directory', 'upgrade', 'tutorial', 'android', 'printer', 'script', 'implement', 'window', 'usb', 'excel', 'sql', 'xml', 'joomla']\n",
    "GamesKeywords = ['game', 'play', 'games', 'online', 'download', 'player', 'forum', 'version', 'copyright', 'casino', 'create', 'club', 'check', 'gaming', 'community', 'team', 'server', 'character', 'win', 'bridge', 'chess', 'tournament', 'puzzle', 'level', 'fantasy', 'war', 'poker', 'development', 'adventure', 'friend', 'wiki', 'rules', 'rpg', 'battle', 'strategy', 'arcade', 'season', 'magic', 'virtual', 'guild', 'nintendo', 'league', 'quest', 'role', 'challenge', 'patch', 'clan', 'chat', 'dragon', 'xbox', 'discord', 'score', 'slot', 'campaign', 'combat', 'pinball', 'fight', 'mod', 'wars', 'winner', 'playing', 'mode', 'bonus', 'multiplayer', 'weapon', 'mission', 'universe', 'tournaments', 'sports', 'beta', 'major', 'playstation', 'players', 'key', 'award', 'dice', 'wow', 'dungeon', 'upgrade', 'kill', 'cheat', 'steam', 'lottery', 'sudoku', 'betting', 'blue', 'gambling', 'gameplay', 'bingo', 'warcraft', 'expansion', 'hero', 'solitaire', 'increase', 'armor', 'beat', 'sims', 'blackjack', 'minecraft', 'collector']\n",
    "HealthKeywords = ['patient', 'services', 'medical', 'treatment', 'pet', 'medicine', 'therapy', 'donate', 'hospital', 'surgery', 'volunteer', 'cancer', 'clinical', 'appointment', 'child', 'disease', 'veterinary', 'emergency', 'clinic', 'pain', 'safety', 'animal', 'body', 'doctor', 'virtual', 'healthcare', 'eye', 'woman', 'check', 'donation', 'recovery', 'healing', 'journal', 'physician', 'nursing', 'heart', 'adult', 'healthy', 'disorder', 'wellness', 'vision', 'provider', 'drug', 'safe', 'treat', 'insurance', 'awareness', 'institute', 'prevention', 'breast', 'loss', 'primary', 'foot', 'physical', 'skin', 'dental', 'stress', 'pregnancy', 'acupuncture', 'vaccine', 'nurse', 'nutrition', 'cat', 'dog', 'testing', 'risk', 'injury', 'addiction', 'surgical', 'ensure', 'weight', 'symptom', 'patients', 'anxiety', 'massage', 'diagnosis', 'consultation', 'women', 'syndrome', 'procedure', 'manage', 'brain', 'blood', 'rehabilitation', 'pharmacy', 'baby', 'laser', 'specialist', 'sleep', 'pediatric', 'medication', 'chronic', 'diet', 'hair', 'vet', 'fertility', 'surgeon', 'cell', 'plastic', 'cosmetic']\n",
    "HomeKeywords =  ['garden', 'family', 'plant', 'recipe', 'child', 'food', 'recipes', 'life', 'grow', 'create', 'guide', 'book', 'easy', 'baby', 'community', 'love', 'resources', 'follow', 'education', 'services', 'sale', 'personal', 'parent', 'gardens', 'change', 'house', 'school', 'water', 'article', 'center', 'gardening', 'build', 'tree', 'store', 'customer', 'cooking', 'kitchen', 'adoption', 'tips', 'chicken', 'fun', 'issue', 'set', 'kid', 'friend', 'cook', 'flower', 'safety', 'play', 'spring', 'stay', 'bring', 'simple', 'healthy', 'require', 'idea', 'space', 'country', 'step', 'green', 'explore', 'eat', 'serve', 'minute', 'orchid', 'style', 'favorite', 'rose', 'seed', 'cake', 'nanny', 'hand', 'perfect', 'light', 'dish', 'chocolate', 'sauce', 'clean', 'hot', 'bread', 'red', 'salad', 'fresh', 'oil', 'sweet', 'ingredient', 'vegetable', 'fruit', 'cheese', 'soup', 'cup', 'rice', 'taste', 'vegan', 'egg', 'bake', 'cream', 'sugar', 'butter', 'salt']\n",
    "NewsKeywords = ['sports', 'local', 'business', 'opinion', 'editor', 'edition', 'media', 'submit', 'online', 'obituaries', 'university', 'entertainment', 'weather', 'police', 'newspaper', 'travel', 'education', 'digital', 'game', 'events', 'culture', 'advertising', 'government', 'country', 'stories', 'editorial', 'magazine', 'advertise', 'president', 'article', 'american', 'trump', 'vaccine', 'journalism', 'district', 'company', 'council', 'archives', 'lifestyle', 'record', 'advertisement', 'baseball', 'law', 'international', 'coronavirus', 'election', 'market', 'canada', 'publish', 'politics', 'basketball', 'technology', 'result', 'listen', 'film', 'death', 'job', 'check', 'science', 'football', 'subscriber', 'current', 'legal', 'valley', 'industry', 'sell', 'access', 'awards', 'journalist', 'build', 'court', 'war', 'subscription', 'department', 'network', 'jobs', 'reporter', 'vote', 'road', 'crime', 'charge', 'lake', 'nation', 'age', 'hit', 'feel', 'development', 'resident', 'friend', 'river', 'grow', 'leader', 'official', 'person', 'car', 'light', 'bank', 'load', 'hotel', 'usd']\n",
    "RecreationKeywords = ['club', 'wine', 'dog', 'book', 'family', 'car', 'breed', 'travel', 'calendar', 'reserve', 'trip', 'guide', 'fishing', 'life', 'fun', 'love', 'map', 'special', 'training', 'road', 'river', 'tour', 'fly', 'activity', 'hunt', 'team', 'puppy', 'water', 'volunteer', 'boat', 'country', 'lake', 'adventure', 'stay', 'rescue', 'collection', 'food', 'friend', 'beer', 'field', 'wines', 'cat', 'hunting', 'bird', 'winery', 'canada', 'safety', 'dive', 'camping', 'mountain', 'ride', 'sailing', 'explore', 'fish', 'valley', 'air', 'drive', 'guest', 'beautiful', 'house', 'school', 'pet', 'yacht', 'trail', 'night', 'diving', 'australia', 'vineyard', 'california', 'equipment', 'flight', 'season', 'weekend', 'cover', 'resort', 'charter', 'spring', 'weather', 'cruise', 'sport', 'win', 'holiday', 'outdoor', 'discover', 'tours', 'race', 'region', 'tasting', 'animal', 'game', 'bear', 'wildlife', 'walk', 'sea', 'lodge', 'scuba', 'islands', 'hotel', 'destination', 'vacation']\n",
    "ReferenceKeywords = ['student', 'university', 'college', 'campus', 'education', 'schedule', 'faculty', 'programs', 'resources', 'library', 'graduate', 'students', 'study', 'learning', 'science', 'academic', 'alumni', 'book', 'class', 'collection', 'department', 'technology', 'undergraduate', 'admission', 'mission', 'studies', 'engineering', 'map', 'institute', 'degree', 'courses', 'teacher', 'exhibit', 'application', 'sciences', 'educational', 'global', 'academics', 'teaching', 'scholarship', 'alumnus', 'collections', 'master', 'registration', 'curriculum', 'hours', 'tuition', 'exhibition', 'professor', 'publications', 'scholarships', 'phd', 'image', 'facilities', 'word', 'teach', 'cultural', 'workshop', 'activities', 'archives', 'grant', 'classroom', 'programme', 'grow', 'catalog', 'academy', 'grade', 'maps', 'honor', 'classes', 'woman', 'institution', 'graduation', 'libraries', 'technical', 'journal', 'degrees', 'colleges', 'housing', 'accreditation', 'exam', 'commencement', 'prospective', 'equity', 'semester', 'athlete', 'postgraduate', 'dean', 'departments', 'math', 'mba', 'ncaa', 'biology', 'requirements', 'bachelor', 'physics', 'honors', 'diploma', 'minor', 'psychology']\n",
    "ScienceKeywords = ['science', 'resources', 'development', 'technology', 'analysis', 'water', 'data', 'study', 'life', 'environmental', 'engineering', 'journal', 'energy', 'scientific', 'testing', 'model', 'material', 'laboratory', 'technical', 'safety', 'institute', 'space', 'human', 'land', 'global', 'lab', 'plant', 'air', 'cell', 'environment', 'conservation', 'food', 'industrial', 'animal', 'method', 'sciences', 'natural', 'impact', 'gas', 'earth', 'registration', 'phd', 'box', 'production', 'physics', 'medical', 'theory', 'manufacturing', 'astronomy', 'volunteer', 'climate', 'chemical', 'function', 'scientist', 'nature', 'biology', 'measurement', 'watch', 'engineer', 'math', 'platform', 'processing', 'marine', 'weather', 'chemistry', 'record', 'australia', 'leadership', 'researcher', 'solar', 'effective', 'county', 'grant', 'specie', 'child', 'category', 'webinar', 'temperature', 'clinical', 'green', 'telescope', 'measure', 'sustainable', 'imaging', 'position', 'wildlife', 'launch', 'waste', 'protein', 'disease', 'dna', 'ocean', 'expand', 'force', 'soil', 'filter', 'molecular', 'organic', 'carbon', 'gene']\n",
    "ShoppingKeywords = ['products', 'sale', 'shipping', 'store', 'stock', 'purchase', 'delivery', 'shopping', 'ship', 'catalog', 'services', 'supply', 'items', 'wholesale', 'checkout', 'category', 'craft', 'pack', 'tool', 'supplies', 'payment', 'produce', 'returns', 'plant', 'categories', 'discount', 'vintage', 'table', 'gear', 'limited', 'reviews', 'metal', 'basket', 'options', 'pet', 'brands', 'organic', 'wishlist', 'clothing', 'designer', 'faqs', 'fabric', 'leather', 'sets', 'sport', 'sports', 'kitchen', 'kids', 'package', 'manufacturer', 'apparel', 'beauty', 'shirt', 'shirts', 'bottle', 'sellers', 'cotton', 'toys', 'shoes', 'diamond', 'dress', 'chairs', 'baskets', 'boots', 'shoe', 'necklaces', 'plants', 'coat', 'dresses', 'womens']\n",
    "SocietyKeywords = ['church', 'worship', 'ministry', 'law', 'sunday', 'god', 'attorney', 'prayer', 'sermon', 'bible', 'parish', 'christ', 'methodist', 'school', 'community', 'jesus', 'firm', 'baptist', 'lawyer', 'legal', 'injury', 'catholic', 'pastor', 'faith', 'accident', 'service', 'christian', 'child', 'youth', 'client', 'funeral', 'yoga', 'mass', 'holy', 'mission', 'family', 'camp', 'presbyterian', 'lutheran', 'litigation', 'donate', 'event', 'united', 'love', 'lodge', 'life', 'online', 'spiritual', 'temple', 'student', 'jewish', 'estate', 'congregation', 'volunteer', 'woman', 'animal', 'jun', 'resource', 'practice', 'retreat', 'bulletin', 'bankruptcy', 'live', 'meeting', 'preschool', 'calendar', 'criminal', 'adult', 'county', 'personal', 'zoom', 'shabbat', 'book', 'study', 'justice', 'court', 'business', 'class', 'chapter', 'meditation', 'post', 'serve', 'divorce', 'patent', 'fellowship', 'gospel', 'association', 'connect', 'music', 'society', 'care', 'unitarian', 'international', 'wedding', 'district', 'saint', 'israel', 'episcopal', 'bishop', 'membership']\n",
    "SportsKeywords = ['golf', 'club', 'horse', 'league', 'race', 'soccer', 'ski', 'football', 'team', 'ride', 'tee', 'coach', 'player', 'bike', 'shot', 'martial', 'hockey', 'rugby', 'aikido', 'season', 'karate', 'ticket', 'class', 'junior', 'game', 'paintball', 'tournament', 'camp', 'play', 'event', 'trail', 'youth', 'hole', 'training', 'news', 'cycling', 'lesson', 'cup', 'academy', 'association', 'sport', 'schedule', 'stallion', 'championship', 'mountain', 'racing', 'sponsor', 'referee', 'tour', 'park', 'farm', 'skate', 'fixture', 'post', 'match', 'art', 'swimming', 'book', 'instructor', 'dojo', 'bicycle', 'country', 'tennis', 'fencing', 'marathon', 'registration', 'track', 'skating', 'surf', 'dressage', 'clubhouse', 'rider', 'swim', 'photo', 'bowling', 'champion', 'field', 'runner', 'run', 'resort', 'sale', 'goal', 'competition', 'trip', 'standing', 'forum', 'breed', 'cricket', 'canoe', 'ranch', 'winger', 'school', 'division', 'mare', 'summer', 'kayak', 'valley', 'save', 'river', 'bowl']\n",
    "\n",
    "def keyword_percentage(text, keywords):\n",
    "    words = text.split()\n",
    "    keyword_count = sum(1 for word in words if word in keywords)\n",
    "    return (keyword_count / len(keywords)) * 100 if words else 0\n",
    "\n",
    "df['AdultKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, AdultKeywords))\n",
    "df['ComputersKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, ComputersKeywords))\n",
    "df['GamesKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, GamesKeywords))\n",
    "df['HealthKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, HealthKeywords))\n",
    "df['NewsKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, NewsKeywords))\n",
    "df['RecreationKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, RecreationKeywords))\n",
    "df['ReferenceKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, ReferenceKeywords))\n",
    "df['ScienceKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, ScienceKeywords))\n",
    "df['ShoppingKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, ShoppingKeywords))\n",
    "df['SocietyKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, SocietyKeywords))\n",
    "df['SportsKeywordPercentage'] = df['clean_content'].apply(lambda x: keyword_percentage(x, SportsKeywords))\n",
    "\n",
    "keyword_columns = ['AdultKeywordPercentage', 'ComputersKeywordPercentage', \n",
    "                   'GamesKeywordPercentage', 'HealthKeywordPercentage',\n",
    "                   'NewsKeywordPercentage', 'RecreationKeywordPercentage', 'ReferenceKeywordPercentage', \n",
    "                   'ScienceKeywordPercentage', 'ShoppingKeywordPercentage', 'SocietyKeywordPercentage', \n",
    "                   'SportsKeywordPercentage']\n",
    "\n",
    "# Scale the keyword percentage features\n",
    "percentagesScaler = MinMaxScaler()\n",
    "keyword_features = percentagesScaler.fit_transform(df[keyword_columns])\n",
    "joblib.dump(percentagesScaler, 'percentagesScaler.joblib')\n",
    "\n",
    "keyword_features = pd.DataFrame(keyword_features, columns=keyword_columns)\n",
    "\n",
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic</th>\n",
       "      <th>academics</th>\n",
       "      <th>academy</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>accreditation</th>\n",
       "      <th>activities</th>\n",
       "      <th>activity</th>\n",
       "      <th>acupuncture</th>\n",
       "      <th>addiction</th>\n",
       "      <th>...</th>\n",
       "      <th>worship</th>\n",
       "      <th>wow</th>\n",
       "      <th>xbox</th>\n",
       "      <th>xhamster</th>\n",
       "      <th>xml</th>\n",
       "      <th>xxx</th>\n",
       "      <th>yacht</th>\n",
       "      <th>yoga</th>\n",
       "      <th>youth</th>\n",
       "      <th>zoom</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.100732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257651</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic  academics   academy  access  accident  accreditation  activities  \\\n",
       "0       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "1       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "2       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "3       0.0        0.0  0.096779     0.0       0.0            0.0         0.0   \n",
       "4       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "\n",
       "   activity  acupuncture  addiction  ...   worship  wow  xbox  xhamster  xml  \\\n",
       "0       0.0          0.0        0.0  ...  0.000000  0.0   0.0       0.0  0.0   \n",
       "1       0.0          0.0        0.0  ...  0.000000  0.0   0.0       0.0  0.0   \n",
       "2       0.0          0.0        0.0  ...  0.000000  0.0   0.0       0.0  0.0   \n",
       "3       0.0          0.0        0.0  ...  0.100732  0.0   0.0       0.0  0.0   \n",
       "4       0.0          0.0        0.0  ...  0.000000  0.0   0.0       0.0  0.0   \n",
       "\n",
       "   xxx  yacht  yoga     youth  zoom  \n",
       "0  0.0    0.0   0.0  0.000000   0.0  \n",
       "1  0.0    0.0   0.0  0.000000   0.0  \n",
       "2  0.0    0.0   0.0  0.000000   0.0  \n",
       "3  0.0    0.0   0.0  0.257651   0.0  \n",
       "4  0.0    0.0   0.0  0.000000   0.0  \n",
       "\n",
       "[5 rows x 879 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "allKeyWords = set(AdultKeywords + ComputersKeywords + GamesKeywords + HealthKeywords + NewsKeywords + RecreationKeywords + ReferenceKeywords + ScienceKeywords + ShoppingKeywords + SocietyKeywords + SportsKeywords)\n",
    "tfidf_final = TfidfVectorizer(vocabulary=allKeyWords)\n",
    "\n",
    "# Fit and transform the whole dataset\n",
    "tfidf_matrix_final = tfidf_final.fit_transform(df['clean_content'])\n",
    "joblib.dump(tfidf_final, 'tfidf_vectorizer.joblib')\n",
    "\n",
    "tfidf_df = pd.DataFrame(tfidf_matrix_final.toarray(), columns=tfidf_final.get_feature_names_out())\n",
    "\n",
    "# Now tfidf_df contains the TF-IDF scores for the whole dataset\n",
    "tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic</th>\n",
       "      <th>academics</th>\n",
       "      <th>academy</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>accreditation</th>\n",
       "      <th>activities</th>\n",
       "      <th>activity</th>\n",
       "      <th>acupuncture</th>\n",
       "      <th>addiction</th>\n",
       "      <th>...</th>\n",
       "      <th>wow</th>\n",
       "      <th>xbox</th>\n",
       "      <th>xhamster</th>\n",
       "      <th>xml</th>\n",
       "      <th>xxx</th>\n",
       "      <th>yacht</th>\n",
       "      <th>yoga</th>\n",
       "      <th>youth</th>\n",
       "      <th>zoom</th>\n",
       "      <th>category_encoded</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.257651</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 879 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic  academics   academy  access  accident  accreditation  activities  \\\n",
       "0       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "1       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "2       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "3       0.0        0.0  0.096779     0.0       0.0            0.0         0.0   \n",
       "4       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "\n",
       "   activity  acupuncture  addiction  ...  wow  xbox  xhamster  xml  xxx  \\\n",
       "0       0.0          0.0        0.0  ...  0.0   0.0       0.0  0.0  0.0   \n",
       "1       0.0          0.0        0.0  ...  0.0   0.0       0.0  0.0  0.0   \n",
       "2       0.0          0.0        0.0  ...  0.0   0.0       0.0  0.0  0.0   \n",
       "3       0.0          0.0        0.0  ...  0.0   0.0       0.0  0.0  0.0   \n",
       "4       0.0          0.0        0.0  ...  0.0   0.0       0.0  0.0  0.0   \n",
       "\n",
       "   yacht  yoga     youth  zoom  category_encoded  \n",
       "0    0.0   0.0  0.000000   0.0                 1  \n",
       "1    0.0   0.0  0.000000   0.0                10  \n",
       "2    0.0   0.0  0.000000   0.0                 3  \n",
       "3    0.0   0.0  0.257651   0.0                 9  \n",
       "4    0.0   0.0  0.000000   0.0                 3  \n",
       "\n",
       "[5 rows x 879 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf_df['category'] = df['category'].reset_index(drop=True)\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "\n",
    "# Initialize the encoder\n",
    "encoder = LabelEncoder()\n",
    "# Encode the category labels\n",
    "tfidf_df['category_encoded'] = encoder.fit_transform(tfidf_df['category'])\n",
    "\n",
    "\n",
    "tfidf_df.drop('category', axis=1, inplace=True)\n",
    "tfidf_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>academic</th>\n",
       "      <th>academics</th>\n",
       "      <th>academy</th>\n",
       "      <th>access</th>\n",
       "      <th>accident</th>\n",
       "      <th>accreditation</th>\n",
       "      <th>activities</th>\n",
       "      <th>activity</th>\n",
       "      <th>acupuncture</th>\n",
       "      <th>addiction</th>\n",
       "      <th>...</th>\n",
       "      <th>title_ComputersKeywordPercentage</th>\n",
       "      <th>title_GamesKeywordPercentage</th>\n",
       "      <th>title_HealthKeywordPercentage</th>\n",
       "      <th>title_NewsKeywordPercentage</th>\n",
       "      <th>title_RecreationKeywordPercentage</th>\n",
       "      <th>title_ReferenceKeywordPercentage</th>\n",
       "      <th>title_ScienceKeywordPercentage</th>\n",
       "      <th>title_ShoppingKeywordPercentage</th>\n",
       "      <th>title_SocietyKeywordPercentage</th>\n",
       "      <th>title_SportsKeywordPercentage</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.096779</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 958 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   academic  academics   academy  access  accident  accreditation  activities  \\\n",
       "0       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "1       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "2       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "3       0.0        0.0  0.096779     0.0       0.0            0.0         0.0   \n",
       "4       0.0        0.0  0.000000     0.0       0.0            0.0         0.0   \n",
       "\n",
       "   activity  acupuncture  addiction  ...  title_ComputersKeywordPercentage  \\\n",
       "0       0.0          0.0        0.0  ...                              0.05   \n",
       "1       0.0          0.0        0.0  ...                              0.00   \n",
       "2       0.0          0.0        0.0  ...                              0.00   \n",
       "3       0.0          0.0        0.0  ...                              0.00   \n",
       "4       0.0          0.0        0.0  ...                              0.00   \n",
       "\n",
       "   title_GamesKeywordPercentage  title_HealthKeywordPercentage  \\\n",
       "0                           0.0                            0.0   \n",
       "1                           0.0                            0.0   \n",
       "2                           0.0                            0.0   \n",
       "3                           0.0                            0.0   \n",
       "4                           0.0                            0.0   \n",
       "\n",
       "   title_NewsKeywordPercentage  title_RecreationKeywordPercentage  \\\n",
       "0                          0.0                                0.0   \n",
       "1                          0.0                                0.0   \n",
       "2                          0.0                                0.0   \n",
       "3                          0.0                                0.0   \n",
       "4                          0.0                                0.0   \n",
       "\n",
       "   title_ReferenceKeywordPercentage  title_ScienceKeywordPercentage  \\\n",
       "0                               0.0                             0.0   \n",
       "1                               0.0                             0.0   \n",
       "2                               0.0                             0.0   \n",
       "3                               0.0                             0.0   \n",
       "4                               0.0                             0.0   \n",
       "\n",
       "   title_ShoppingKeywordPercentage  title_SocietyKeywordPercentage  \\\n",
       "0                         0.166667                             0.0   \n",
       "1                         0.000000                             0.0   \n",
       "2                         0.000000                             0.0   \n",
       "3                         0.000000                             0.0   \n",
       "4                         0.000000                             0.0   \n",
       "\n",
       "   title_SportsKeywordPercentage  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "\n",
       "[5 rows x 958 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest, chi2\n",
    "import numpy as np\n",
    "\n",
    "# Separate features and target\n",
    "X = tfidf_df.drop('category_encoded', axis=1) \n",
    "y = tfidf_df['category_encoded']  # Labels\n",
    "\n",
    "# Concatenate the HTML features, keyword features, topic features, and bigram features with the selected features\n",
    "combined_features = np.hstack((X.values, html_text_features.values, keyword_features.values, topic_features.values, meta_title_keyword_features.values))\n",
    "combined_feature_names = list(X.columns) + html_text_feature_columns + keyword_columns + topic_features.columns.tolist() + meta_title_keyword_columns\n",
    "combined_df = pd.DataFrame(combined_features, columns=combined_feature_names)\n",
    "combined_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined DataFrame size: (99086, 958)\n",
      "DataFrame size: (99086, 69)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Combined DataFrame size: {combined_df.shape}\")\n",
    "print(f\"DataFrame size: {df.shape}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyCaret)",
   "language": "python",
   "name": "pycaret_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
