{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0...</td>\n",
       "      <td>Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\r\\n&lt;html lang=\"en-US\" class=\"u...</td>\n",
       "      <td>Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.1//...</td>\n",
       "      <td>Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;!doctype html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;meta cha...</td>\n",
       "      <td>Games</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "      <td>Games</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content category\n",
       "0  \\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0...    Games\n",
       "1  <!DOCTYPE html>\\r\\n<html lang=\"en-US\" class=\"u...    Games\n",
       "2  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.1//...    Games\n",
       "3  <!doctype html><html lang=\"en\"><head><meta cha...    Games\n",
       "4  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...    Games"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas as pd\n",
    "import gc\n",
    "\n",
    "# Establish connection using SQLAlchemy\n",
    "engine = create_engine('postgresql+psycopg2://postgres:password@localhost:5432/dataset_bakalarka')\n",
    "\n",
    "query = \"\"\"\n",
    "SELECT content, category\n",
    "FROM (\n",
    "  SELECT content, category,\n",
    "         ROW_NUMBER() OVER (PARTITION BY category ORDER BY RANDOM()) AS rn\n",
    "  FROM web_data\n",
    "  WHERE category = 'Games'\n",
    ") sub\n",
    "WHERE rn <= 100000\n",
    "\"\"\"\n",
    "\n",
    "chunks = []\n",
    "for chunk in pd.read_sql_query(query, engine, chunksize=10000):\n",
    "    chunks.append(chunk)\n",
    "\n",
    "df = pd.concat(chunks, ignore_index=True)\n",
    "del chunks\n",
    "gc.collect()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\melou\\AppData\\Local\\Temp\\ipykernel_35560\\2064381985.py:4: XMLParsedAsHTMLWarning: It looks like you're parsing an XML document using an HTML parser. If this really is an HTML document (maybe it's XHTML?), you can ignore or filter this warning. If it's XML, you should know that using an XML parser will be more reliable. To parse this document as XML, make sure you have the lxml package installed, and pass the keyword argument `features=\"xml\"` into the BeautifulSoup constructor.\n",
      "  soup = BeautifulSoup(text, \"lxml\")\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "Games    6404\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "\n",
    "def clean_html(text):\n",
    "    soup = BeautifulSoup(text, \"lxml\")\n",
    "    body = soup.body\n",
    "    return body.get_text(separator=\" \") if body else \"\"\n",
    "\n",
    "df['clean_content'] = df['content'].apply(clean_html)\n",
    "df.head()\n",
    "df['category'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Is GPU enabled: True\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "\n",
    "is_gpu_enabled = spacy.require_gpu()\n",
    "print(f\"Is GPU enabled: {is_gpu_enabled}\")\n",
    "nlp = spacy.load('en_core_web_md')\n",
    "nlp.max_length = 5000000\n",
    "\n",
    "def lemmatize_text(text):\n",
    "    # Process the text through the spaCy NLP pipeline\n",
    "    doc = nlp(text)\n",
    "    # Return the lemmatized text\n",
    "    return \" \".join([token.lemma_ for token in doc])\n",
    "\n",
    "df['clean_content'] = df['clean_content'].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of non-English samples removed: 110\n"
     ]
    }
   ],
   "source": [
    "from langdetect import detect\n",
    "\n",
    "def is_english(text):\n",
    "    try:\n",
    "        return detect(text) == 'en'\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "# Apply the language detection function\n",
    "df['is_english'] = df['clean_content'].apply(is_english)\n",
    "\n",
    "# Calculate the number of non-English samples\n",
    "non_english_count = df['is_english'].value_counts().get(False, 0)\n",
    "print(f\"Number of non-English samples removed: {non_english_count}\")\n",
    "\n",
    "# Filter out non-English samples\n",
    "df = df[df['is_english']].drop(columns=['is_english'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>content</th>\n",
       "      <th>category</th>\n",
       "      <th>clean_content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0...</td>\n",
       "      <td>Games</td>\n",
       "      <td>keyblades hearts offline hearts trailer mercha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;!DOCTYPE html&gt;\\r\\n&lt;html lang=\"en-US\" class=\"u...</td>\n",
       "      <td>Games</td>\n",
       "      <td>ufstarfleet ufstarfleet discover ufstarfleet t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.1//...</td>\n",
       "      <td>Games</td>\n",
       "      <td>gameboy mame cheat files tools simply massive ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>&lt;!doctype html&gt;&lt;html lang=\"en\"&gt;&lt;head&gt;&lt;meta cha...</td>\n",
       "      <td>Games</td>\n",
       "      <td>achievement xbox xbox arcade xbox application ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>&lt;!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...</td>\n",
       "      <td>Games</td>\n",
       "      <td>games detailed spec regard game console tomb r...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             content category  \\\n",
       "0  \\n<!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.0...    Games   \n",
       "1  <!DOCTYPE html>\\r\\n<html lang=\"en-US\" class=\"u...    Games   \n",
       "2  <!DOCTYPE html PUBLIC \"-//W3C//DTD XHTML 1.1//...    Games   \n",
       "3  <!doctype html><html lang=\"en\"><head><meta cha...    Games   \n",
       "4  <!DOCTYPE HTML PUBLIC \"-//W3C//DTD HTML 4.01 T...    Games   \n",
       "\n",
       "                                       clean_content  \n",
       "0  keyblades hearts offline hearts trailer mercha...  \n",
       "1  ufstarfleet ufstarfleet discover ufstarfleet t...  \n",
       "2  gameboy mame cheat files tools simply massive ...  \n",
       "3  achievement xbox xbox arcade xbox application ...  \n",
       "4  games detailed spec regard game console tomb r...  "
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "import string\n",
    "\n",
    "\n",
    "with open(\"stopwords-en.txt\", \"r\") as file:\n",
    "    stopwords_list = file.read().splitlines()\n",
    "\n",
    "stopwords = set(stopwords_list)\n",
    "custom_stopwords = set([\n",
    "    'contact', 'service', 'policy', 'site', 'privacy', 'support', 'email', 'blog',\n",
    "    'post', 'learn', 'read', 'offer', 'provide', 'include', 'click', 'update',\n",
    "    'feature', 'link', 'search', 'website', 'program', 'start', 'view', 'resource',\n",
    "    'experience', 'list', 'free', 'info', 'shop', 'video', 'share', 'member',\n",
    "    'add', 'start', 'work', 'order', 'day', 'people', 'history', 'office',\n",
    "    'time', 'year', 'event', 'national', 'state', 'high', 'month', 'week', 'open',\n",
    "    'cookies', 'menu', 'cart', 'browser', 'select', 'choose', 'hope', 'enjoy', 'disabled',\n",
    "    'facebook', 'twitter', 'youtube', 'instagram', 'account', 'cookie', 'subscribe',\n",
    "    'newsletter', 'sign', 'message', 'comment', 'form', 'login', 'user', 'member',\n",
    "    'join', 'write', 'update', 'search', 'review',\n",
    "    'january', 'february', 'march', 'april', 'may', 'june', 'july', 'august',\n",
    "    'september', 'october', 'november', 'december', 'year', 'today', 'yesterday', 'tomorrow', 'datum', 'date',\n",
    "    'jan', 'feb', 'mar', 'apr', 'may', 'jun', 'jul', 'aug', 'sep', 'oct', 'nov', 'dec',\n",
    "    'monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday', 'mon', 'tue', 'wed', 'thu', 'fri', 'sat', 'sun',\n",
    "    'regional', 'albuquerque', 'chicago', 'minneapolis', 'philadelphia', 'phoenix', 'rhode', 'island', 'scottsdale', 'washington', 'wisconsin', 'michigan',\n",
    "    'bay', 'beach', 'dakota', 'florida', 'georgia', 'hampshire', 'harbor', 'iowa', 'maine',  'missouri', 'park', 'virginia', 'vista', 'wisconsin', 'massachusetts',\n",
    "    'minnesota',\n",
    "    'skip', 'content', 'main', 'term', 'condition', 'toggle', 'navigation', 'wordpress', 'social', 'medium', 'upcoming', 'event',\n",
    "    'photo', 'gallery', 'news', 'frequently', 'question', 'ask', 'press', 'release', 'quick', 'link', 'continue', 'read', 'phone', 'fax', 'answer', 'question',\n",
    "    'board', 'director', 'real', 'estate', 'los', 'angeles', 'new', 'york', 'city', 'san', 'francisco', 'power', 'united', 'kingdom', 'states', 'america', 'fran', 'ais',\n",
    "    'north', 'carolina', 'las', 'vegas', 'annual', 'report', 'highly', 'recommend', 'rss', 'feed', 'white', 'paper', 'hong', 'kong', 'credit', 'card', 'mental', 'health', 'public', 'save', 'money',\n",
    "    'annual', 'meeting', 'wide', 'range', 'care', 'gift', 'professional', 'live', 'stream', 'quality', 'product', 'project', 'management', 'meet', 'nonprofit', 'organization', 'blogthis', 'pinter',\n",
    "    'design', 'success', 'story', 'summer', 'camp', 'chain', 'register', 'trademark', 'username', 'password', 'certificate', 'plan', 'visit', 'regular', 'price', 'covid', 'pandemic', 'south', 'africa', 'west', 'east', 'regional',\n",
    "\n",
    "    # Games\n",
    "    'close', 'change', 'fun', 'map', 'guide', 'file', 'book', 'set', 'late', 'base', 'software', 'follow', 'code', 'store', 'easy', 'build', 'result', 'posts', 'word', 'life',\n",
    "    'log', 'archive', 'star', 'lot', 'rule', 'complete', 'item', 'space', 'send', 'series', 'current', 'special', 'table', 'hour', 'leave', 'age', 'classic', 'love', 'note', 'race', 'feel',\n",
    "    'pick', 'machine', 'edition', 'final', 'dark', 'hand', 'action', 'topic', 'article', 'issue', 'party', 'type', 'bet', 'black', 'total', 'skill', 'option', 'gold', 'hold', 'king',\n",
    "    'links', 'faq', 'enter', 'fast', 'forums', 'host', 'company', 'source', 'entertainment', 'fan', 'official', 'image', 'windows', 'art', 'events', 'music', 'original', 'access', 'family',\n",
    "    'bit', 'require', 'bring', 'future', 'bug', 'discussion', 'mobile', 'class', 'pack', 'super', 'house', 'control', 'night', 'title', 'popular', 'daily', 'hard', 'unit',\n",
    "    'receive', 'horse', 'master', 'racing', 'improve', 'match', 'hotel', 'prize', 'hit', 'pro', 'pass', 'championship', 'gain', \n",
    "    'stuff', 'address', 'tool', 'business', 'internet', 'model', 'collection', 'idea', 'theme', 'happy', 'sale', 'screen', 'return', 'watch', 'sell', 'remember', 'talk', 'simple',\n",
    "    'category', 'draw', 'lead', 'lose', 'affiliate', 'minute', 'entry', 'red', 'style', 'pay', 'force', 'happen', 'deal', 'football', 'chance', 'pool', 'piece', 'attack', 'cup',\n",
    "    'reserve', 'english', 'staff', 'stay', 'explore', 'box', 'guest', 'schedule', 'sound', 'publish', 'unique', 'location', 'purchase', 'reviews', 'cover', 'finally', 'school',\n",
    "    'decide', 'light', 'speed', 'land', 'step', 'standard', 'single', 'pretty', 'break', 'bad', 'thread', 'rank', 'switch',\n",
    "    'mail', 'customer', 'random', 'develop', 'previous', 'custom', 'track', 'fall', 'ship', 'app', 'mark', 'favorite', 'edit', 'platform',\n",
    "    'monster', 'head', 'person', 'international', 'core', 'sport', 'brand', 'legend', 'grand', 'cash', 'double',\n",
    "    'submit', 'picture', 'database', 'engine', 'print', 'center', 'color', 'library', 'notice', 'market', 'modern', 'field', 'advanced', 'finish', 'drop', 'rate', 'ticket',\n",
    "    'earn', 'elite', 'personal', 'graphic', 'farm', 'ready', 'active', 'country', 'wait', 'calendar', 'command', 'basic', 'partner', 'local', 'expect',\n",
    "    'record', 'choice', 'heroes', 'media', 'language', 'developer', 'flight', 'letter', 'focus', 'mind', 'apply', 'cost', 'death', 'limit', 'ability', 'details', 'tour', 'quiz',\n",
    "    'relate', 'activity', 'network', 'format', 'articles', 'technology', 'bar', 'american', 'short', 'john', 'vote', 'rating', 'client', 'author', 'movie', 'tips', 'membership', 'reach',\n",
    "    'guy', 'nice', 'reason', 'die', 'button', 'guides', 'usa', 'pre', 'session', 'ultimate', 'ball', 'roll', 'reward', 'registration', 'load', 'drive', 'dead', 'window', 'discuss',\n",
    "    'grow', 'display', 'remove', 'competition', 'connect', 'addition', 'travel',\n",
    "\n",
    "\n",
    "    \n",
    "])\n",
    "stopwords.update(custom_stopwords)\n",
    "stopwords = sorted(stopwords)\n",
    "\n",
    "# Function to further clean the text\n",
    "def further_clean_text(text, stopwords):\n",
    "    # Normalize spaces; replaces all kinds of whitespace with a single space\n",
    "    text = re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "    # Remove all numbers (digits) from the text\n",
    "    text = re.sub(r'\\d+', '', text)\n",
    "\n",
    "    # Remove non-English characters\n",
    "    text = re.sub(r'[^\\x00-\\x7F]+', ' ', text)\n",
    "\n",
    "    # Remove punctuation\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "\n",
    "    # Convert text to lower case to standardize for stopwords removal\n",
    "    text = text.lower()\n",
    "\n",
    "    # Split text into words, remove short words and stopwords\n",
    "    text = ' '.join([word for word in text.split() if len(word) >= 3 and word not in stopwords])\n",
    "    text = text.strip()\n",
    "\n",
    "    return text\n",
    "\n",
    "df['clean_content'] = df['clean_content'].apply(lambda x: further_clean_text(x, stopwords))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['game', 'play', 'games', 'online', 'download', 'player', 'forum', 'version', 'copyright', 'casino', 'create', 'club', 'check', 'gaming', 'community', 'team', 'server', 'character', 'win', 'bridge', 'chess', 'tournament', 'puzzle', 'level', 'fantasy', 'war', 'poker', 'development', 'adventure', 'friend', 'wiki', 'rules', 'rpg', 'battle', 'strategy', 'arcade', 'season', 'magic', 'virtual', 'guild', 'nintendo', 'league', 'quest', 'role', 'challenge', 'patch', 'clan', 'chat', 'dragon', 'xbox', 'discord', 'score', 'slot', 'campaign', 'combat', 'pinball', 'fight', 'mod', 'wars', 'winner', 'playing', 'mode', 'bonus', 'multiplayer', 'weapon', 'mission', 'universe', 'tournaments', 'sports', 'beta', 'major', 'playstation', 'players', 'key', 'award', 'dice', 'wow', 'dungeon', 'upgrade', 'kill', 'cheat', 'steam', 'lottery', 'sudoku', 'betting', 'blue', 'gambling', 'gameplay', 'bingo', 'warcraft', 'expansion', 'hero', 'solitaire', 'increase', 'armor', 'beat', 'sims', 'blackjack', 'minecraft', 'collector']\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import numpy as np\n",
    "\n",
    "vectorizer = TfidfVectorizer(max_features=100, stop_words='english')\n",
    "tfidf_matrix = vectorizer.fit_transform(df['clean_content'])\n",
    "\n",
    "feature_names = vectorizer.get_feature_names_out()\n",
    "mean_tfidf = np.asarray(tfidf_matrix.mean(axis=0)).flatten()\n",
    "top_keywords = [feature_names[i] for i in mean_tfidf.argsort()[::-1]]\n",
    "\n",
    "# Print as a Python array\n",
    "print(top_keywords)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (PyCaret)",
   "language": "python",
   "name": "pycaret_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
